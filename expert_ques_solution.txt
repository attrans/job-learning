专家结对代码可靠性走查, 待走查代码:
1. qualcommon数据库连接获取超时, 导致容器重启
----针对此类问题, 解决手段除了增加最大连接数以外, 需要分析问题的原因, 主要思路有:
	1) 限制并发数
	2) 提升数据库操作的效率 ---- 任务表及其相关表的数据量很小, 访问应该是很快的
	3) 工作流activiti能否使用另外的一套配置 ---- 根据思路, 查看了activiti的数据库连接配置, 发现最大连接数配的是1, 结合外场的启动时部署工作流获取数据库连接失败的现象, 判断可能是这里的配置有问题. 可能需要尝试复现问题, 调大这里的配置, 并且评估影响
2. 中台数据查询方案优化
----问题主要包含两个方面: 
	1. 由于在where条件拼接了8000小区的查询条件, 导致sql超长
	---- 1) 可以考虑使用中间表, 将8000小区的查询条件放在表里, 再跟数据表进行联合查询
	---- 2) 分批次拼接小区再查询, 比如一次拼1000小区
	2. 查询效率优化
	---- 1) 增加关键查询列的索引
	---- 2) 根据情况1的效果, 判断是否需要仍使用中间表联合查询
3. 弹缩调度
----此类问题考虑是否是消息乱序问题, 可以使用TLA+工具, 模拟程序运行, 模拟并发条件, 来进行检查
----同时建议对于偶现问题, 也要找原因, 评估影响, 没有解决方案也一定要有规避方案
4. 合并报告
----合并报告耗时长, 主要有两个瓶颈:
	1. 从数据库查询数据耗时长
	---- 1) 最大数据条数达到几百万级别, 现在的方案使用limit+offset查询, 每次查询1万条, 这种方式会由于查询数据的数量越来越多导致越来越慢, 并且使用的排序字段是指标值(并且重复很多), 不好直接从数据库角度考虑分批策略和索引策略
	---- 2) 考虑从业务层面, 将KPI质差小区数据查询拆分成按指标多次查询, 根据效果再看是否要再按天进行进一步细化查询粒度, 控制每次查询的数据量. 不再使用limit+offset模式.
	---- 3) 其实可以考虑使用流式读写查询结果ResultSet: 
		Statement st = conn.createStatement(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);
		BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(csvFile, true), StandardCharsets.UTF_8), 8192);
		CSVWriter writer = new CSVWriter(bw, CSVWriter.DEFAULT_SEPARATOR, CSVWriter.DEFAULT_QUOTE_CHARACTER, CSVWriter.DEFAULT_ESCAPE_CHARACTER, CSVWriter.DEFAULT_LINE_END);
		result = st.executeQuery(sql);
		if (!rs.isBeforeFirst()) {
			return 1;
		}
		writer.writeAll(rs, false);
		return 0;
	2. 从数据库查回来的数据写入xlsx耗时长
	---- 1) 由于目前是直接写入的pvc盘, 写入慢的原因可能是因为网络io慢, 考虑是否合并报告先写在本地盘, 再复制到pvc
	---- 2) 考虑是否可以多线程写xlsx
5. 定时清理代码
----没有再走查这里的代码, 有两点注意:
	1. 删除文件需要校验返回值, 确保删除成功
	2. 定时任务需要捕获所有异常, 否则导致定时器挂掉, 会影响当前定时器的其他所有定时任务执行
	---- 1) 打印线程栈, 看定时器是否还存在
	---- 2) 增加自愈方案, 重启定时器
6. kafka消息丢失异常处理
----目前主要考虑两点异常:
	1. kafka消息丢失
	---- 1) 明确是生产者没有发送, 还是消费者没有收到
	---- 2) 确认消费消息是否出现异常
	2. kafka消息消费失败
	---- 1) 可以不要用默认策略, 改为手动提交, 处理完再提交偏移量, 保证消费成功. 可能存在重复消费, 业务也需要考虑应对策略.
	---- 2) 生产者提交, 也要进行状态确认, 确认消息是否真正到达kafka, 根据提交返回的结果进行确认
7. OOM问题:
----此类问题的处理经验:
	1. 限流, 在用户入口进行限制
	2. 根据容量, 来限制任务数/并发数
	3. 精细化控制(配置吴黎华团队已实现), 针对每种业务的内存使用估算(计算并发能力), 设置全局信号量, 根据信号量做减法, 判断是否拒绝后续业务
	4. javaaf提供的基于内存控制方法, 咨询王思霏
	5. 也要考虑非堆溢出, 毛志勇牵头梳理的jvm配置; 谨慎使用或者不要使用直接内存

1. 限制并发数
2. 提升数据库效率
3. 工作流数据库最大连接数1, 是否需要调大, 影响评估, 问题复现
4. 中间表, 联合查询, 减少sql长度, 测试效率; 分批查询
5. 增加索引
6. TLA+模拟程序运行, 并发, 检查是否存在消息乱序问题
7. 偶现问题, 找原因, 评估影响, 规避方案 

KPI质差小区数据查询拆分成按指标多次查询
合并报告先落地到本地盘，再复制到pvc
多线程写xlsx

删除文件需要校验返回值
定时任务捕获所有异常， 否则导致定时器挂掉， 是否会影响其它所有定时任务执行， 打印线程栈， 看定时器是否还存在； 增加自愈方案， 重启定时器

kafka消息消费失败， 是否需要重新消费； 手动提交， 处理完再提交偏移量； 生产者提交， 状态确认， 消息是否真正到达kafka， 确认结果
kafka消息丢失， 消费者没有收到： 确认消费消息是否出现异常； 

OOM问题： 
1. 限流， 用户入口
2. 容量， 任务数， 并发数
3. 精细化控制（吴黎华团队）， 每种业务内存使用估算（计算并发能力）， 全局信号量， 根据信号量做减法， 判断是否拒绝后续业务
4. Javaaf提供的基于内存控制方法， 咨询王思霏
5. 非堆溢出， 毛志勇牵头梳理的jvm配置； 直接内存配置， 谨慎使用


可靠性：
任务里保证进度完成
中间件以及调用微服务异常重试， 5分钟
启动流程保证每一步成功
起线程的启动逻辑， 业务保证成功
pg启动， 5分钟， 异常重试5分钟


走查代码的目的是什么, 一定要明确
BA走查: 业务逻辑
开发走查: 代码漏洞, 异常处理, cleancode等
专家走查: 实现方式, 可靠性, 效率等
